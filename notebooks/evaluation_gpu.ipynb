{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb355a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: final_decision_transformer_model3.pt\n"
     ]
    }
   ],
   "source": [
    "#Importamos las librerías que vamos a usar\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from dr import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuración general\n",
    "DATASET = \"netflix\"\n",
    "NUM_ITEMS = 752 \n",
    "NUM_GROUPS = 8\n",
    "CONTEXT_LENGTH = 20\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Rutas\n",
    "root = Path(\"..\").resolve()\n",
    "processed_path = root / \"data\" / \"processed\" / \"trajectories_train.pkl\"\n",
    "test_path = root / \"data\" / \"test_users\" / \"netflix8_test.json\"\n",
    "\n",
    "# Cargar trayectorias de training\n",
    "with open(processed_path, \"rb\") as f:\n",
    "    train_trajectories = pickle.load(f)\n",
    "\n",
    "# Cargar usuarios de test\n",
    "with open(test_path, \"r\") as f:\n",
    "    test_users = json.load(f)\n",
    "\n",
    "# Instanciar el modelo con los hiperparámetros que te pasó tu amiga\n",
    "model = DecisionTransformer(\n",
    "    num_items=752, \n",
    "    num_groups=8, \n",
    "    hidden_dim=512, \n",
    "    n_layers=2, \n",
    "    n_heads=4, \n",
    "    context_length=25, \n",
    "    max_timestep=200, \n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# Cargar pesos entrenados\n",
    "ckpt_path = Path(\"final_decision_transformer_model3.pt\")  # ajustá ruta si está en otra carpeta\n",
    "state_dict = torch.load(ckpt_path, map_location=DEVICE)\n",
    "model.load_state_dict(state_dict)  # ahora debería decir: <All keys matched successfully>\n",
    "\n",
    "# Preparar para inferencia\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(\"Modelo cargado desde:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c36fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from math import log2\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_batched(\n",
    "    model,\n",
    "    test_data,\n",
    "    device,\n",
    "    target_return=None,\n",
    "    k_list=(5, 10, 20),\n",
    "    context_len=20,\n",
    "    eval_batch_size=1024\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluación batcheada y GPU-native para usuarios con longitudes distintas.\n",
    "\n",
    "    Args:\n",
    "        model: Decision Transformer que acepta (states, actions, rtg, timesteps, groups)\n",
    "        test_data: lista de dicts {'group': int, 'items': List[int], 'ratings': List[float]}\n",
    "        device: torch.device\n",
    "        target_return: float or None (si None usa suma de ratings de la ventana)\n",
    "        k_list: tupla/lista de K para métricas\n",
    "        context_len: longitud de la historia a usar (ventana)\n",
    "        eval_batch_size: tamaño de batch para la inferencia (ajustar por memoria)\n",
    "    Returns:\n",
    "        dict con HR@k, NDCG@k, MRR (floats)\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 1) Construir dataset de ventanas (en CPU) - cada muestra = una historia de length context_len + target\n",
    "    states_list = []\n",
    "    actions_list = []\n",
    "    rtg_list = []\n",
    "    groups_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    for user in test_data:\n",
    "        group = int(user['group'])\n",
    "        items = user['items']\n",
    "        ratings = user['ratings']\n",
    "\n",
    "        L = len(items)\n",
    "        if L <= context_len:\n",
    "            continue  # no hay ventana válida\n",
    "\n",
    "        # generar ventanas\n",
    "        for t in range(context_len, L):\n",
    "            hist_items = items[t-context_len:t]               # length = context_len\n",
    "            hist_ratings = ratings[t-context_len:t]\n",
    "\n",
    "            rtg_val = (sum(hist_ratings) if target_return is None else float(target_return))\n",
    "\n",
    "            states_list.append(hist_items)\n",
    "            actions_list.append(hist_items)   # en tu código original actions == states\n",
    "            rtg_list.append([rtg_val] * context_len)  # replicar por paso temporal si tu modelo espera RTG por paso\n",
    "            groups_list.append(group)\n",
    "            targets_list.append(items[t])\n",
    "\n",
    "    # Si no hay muestras válidas\n",
    "    if len(states_list) == 0:\n",
    "        return {f'HR@{k}': 0.0 for k in k_list} | {f'NDCG@{k}': 0.0 for k in k_list} | {'MRR': 0.0}\n",
    "\n",
    "    # 2) Convertir todo a tensores y mover a device UNA VEZ (evita múltiples CPU->GPU)\n",
    "    states = torch.tensor(states_list, dtype=torch.long, device=device)        # (N, context_len)\n",
    "    actions = torch.tensor(actions_list, dtype=torch.long, device=device)      # (N, context_len)\n",
    "    rtg = torch.tensor(rtg_list, dtype=torch.float32, device=device).unsqueeze(-1)  # (N, context_len, 1)\n",
    "    groups = torch.tensor(groups_list, dtype=torch.long, device=device)        # (N,)\n",
    "    targets = torch.tensor(targets_list, dtype=torch.long, device=device)      # (N,)\n",
    "\n",
    "    N = states.size(0)\n",
    "    num_ks = len(k_list)\n",
    "\n",
    "    # Precompute timesteps (se puede broadcastear por batch)\n",
    "    # Model en tu ejemplo aceptaba timesteps shape (batch, context_len)\n",
    "    timesteps_single = torch.arange(context_len, dtype=torch.long, device=device).unsqueeze(0)  # (1, context_len)\n",
    "\n",
    "    # 3) Acumuladores para métricas (mantener en GPU)\n",
    "    hr_sums = torch.zeros(num_ks, device=device, dtype=torch.float64)   # usamos float64 para mayor estabilidad al acumular\n",
    "    ndcg_sums = torch.zeros(num_ks, device=device, dtype=torch.float64)\n",
    "    mrr_sum = torch.tensor(0.0, device=device, dtype=torch.float64)\n",
    "    total = 0\n",
    "\n",
    "    # Precompute denominators for NDCG (log2 ranks)\n",
    "    max_k = max(k_list)\n",
    "    ranks = torch.arange(1, max_k + 1, device=device, dtype=torch.float32)  # (max_k,)\n",
    "    discount = torch.log2(ranks + 1.0)  # (max_k,)\n",
    "\n",
    "    # 4) Inferencia en mini-batches\n",
    "    for start in range(0, N, eval_batch_size):\n",
    "        end = min(start + eval_batch_size, N)\n",
    "        b = end - start\n",
    "\n",
    "        s_batch = states[start:end]           # (b, context_len)\n",
    "        a_batch = actions[start:end]          # (b, context_len)\n",
    "        r_batch = rtg[start:end]              # (b, context_len, 1)\n",
    "        g_batch = groups[start:end]           # (b,)\n",
    "        t_batch = targets[start:end]          # (b,)\n",
    "\n",
    "        # timesteps repeat para el batch\n",
    "        ts_batch = timesteps_single.expand(b, -1)  # (b, context_len)\n",
    "\n",
    "        # forward (asume salida logits (b, seq_len, num_items) )\n",
    "        logits = model(s_batch, a_batch, r_batch, ts_batch, g_batch)  # (b, seq_len, num_items)\n",
    "        preds = logits[:, -1, :]   # (b, num_items)  <-- scores para cada item\n",
    "\n",
    "        # --- HR@K and NDCG@K ---\n",
    "        # obtener top max_k indices y scores\n",
    "        topk_vals, topk_idx = torch.topk(preds, k=max_k, dim=1)  # (b, max_k)\n",
    "        # targets comparacion\n",
    "        # shape targets -> (b,1) for broadcasting\n",
    "        eq = (topk_idx == t_batch.unsqueeze(1))  # (b, max_k) bool\n",
    "\n",
    "        # Para cada K en k_list computar HR y NDCG\n",
    "        for i, k in enumerate(k_list):\n",
    "            eq_k = eq[:, :k]                                 # (b, k)\n",
    "            hits = eq_k.any(dim=1).to(torch.float32)         # (b,)\n",
    "            hr_sums[i] += hits.sum().to(torch.float64)\n",
    "\n",
    "            # NDCG: relevance is 1 only where eq_k True, DCG = sum(relevance / log2(rank+1))\n",
    "            # discount[:k] -> (k,)\n",
    "            relevance = eq_k.to(torch.float32)              # (b, k)\n",
    "            dcg = (relevance / discount[:k]).sum(dim=1)     # (b,)\n",
    "            ndcg_sums[i] += dcg.sum().to(torch.float64)\n",
    "\n",
    "        # --- MRR ---\n",
    "        # Fast rank calculation without sorting fully:\n",
    "        # rank_i = 1 + sum_j (preds_ij > preds_i,target)\n",
    "        # target scores\n",
    "        idx = torch.arange(preds.size(0), device=device)\n",
    "        target_scores = preds[idx, t_batch]                 # (b,)\n",
    "        # count how many items have strictly greater score than target score\n",
    "        better_count = (preds > target_scores.unsqueeze(1)).sum(dim=1).to(torch.float32)  # (b,)\n",
    "        ranks_tensor = better_count + 1.0\n",
    "        rr = (1.0 / ranks_tensor).to(torch.float64)        # (b,)\n",
    "        mrr_sum += rr.sum()\n",
    "\n",
    "        total += b\n",
    "\n",
    "    # 5) Calcular promedios finales (mover a CPU 1 vez con .item())\n",
    "    result = {}\n",
    "    total = float(total)  # convertir a float Python\n",
    "\n",
    "    for i, k in enumerate(k_list):\n",
    "        result[f'HR@{k}'] = float((hr_sums[i] / total).item())\n",
    "        result[f'NDCG@{k}'] = float((ndcg_sums[i] / total).item())\n",
    "\n",
    "    result['MRR'] = float((mrr_sum / total).item())\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a468f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HR@5': 0.006830601092896175,\n",
       " 'NDCG@5': 0.004585265277431963,\n",
       " 'HR@10': 0.014343408469945355,\n",
       " 'NDCG@10': 0.00696252257385052,\n",
       " 'HR@20': 0.030364583333333334,\n",
       " 'NDCG@20': 0.010931653772058382,\n",
       " 'MRR': 0.010711217664413367}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_batched(model, test_users, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537596e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
