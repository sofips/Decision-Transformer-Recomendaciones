{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e43b8-2be8-4fdb-9b95-eec507f0bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "#Importamos las librerías que vamos a usar\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.decision_transformer import DecisionTransformer\n",
    "from reference_code.dt_reference import DecisionTransformerReference\n",
    "from src.models.baselines import PopularityRecommender\n",
    "\n",
    "from scripts.evaluation import evaluate_model_batched\n",
    "\n",
    "\n",
    "# Reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6085520",
   "metadata": {},
   "source": [
    "# Experimentos de return conditioning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5ea442-bf68-4a93-91c3-0718b7f790e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas\n",
    "test_path = \"../data/test_users/netflix8_test.json\"\n",
    "\n",
    "final_model_path = \"../results/trained_models/final_decision_transformer_model_refactored.pt\"\n",
    "reference_model_path = \"../reference_code/trained_model_2025-12-01_11-30-57.pt\"\n",
    "\n",
    "# Cargar usuarios de test\n",
    "with open(test_path, \"r\") as f:\n",
    "    test_users = json.load(f)\n",
    "    \n",
    "# Cargar trayectorias de entrenamiento normalizadas\n",
    "train_trajectories_path = \"../data/processed/trajectories_train.pkl\"\n",
    "with open(train_trajectories_path, \"rb\") as f:\n",
    "    train_trajectories = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9361941-c1d4-4c7e-b625-716eba0f5ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: ../results/trained_models/final_decision_transformer_model_refactored.pt\n"
     ]
    }
   ],
   "source": [
    "num_items = 752\n",
    "num_groups = 8\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "context_length = 25\n",
    "max_timesteps = 200\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Initialize model\n",
    "final_model = DecisionTransformer(\n",
    "    num_items=752,\n",
    "    num_groups=8,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    n_heads=n_heads,\n",
    "    context_length=context_length,\n",
    "    max_timestep=max_timesteps,\n",
    "    dropout=dropout\n",
    ").to('cuda')\n",
    "\n",
    "# Cargar pesos entrenados\n",
    "ckpt_path = Path(final_model_path)  # ajustá ruta si está en otra carpeta\n",
    "state_dict = torch.load(ckpt_path, map_location=DEVICE)\n",
    "final_model.load_state_dict(state_dict)  # ahora debería decir: <All keys matched successfully>\n",
    "\n",
    "# Preparar para inferencia\n",
    "final_model.to(DEVICE)\n",
    "final_model.eval()\n",
    "\n",
    "print(\"Modelo cargado desde:\", ckpt_path)\n",
    "\n",
    "final_model_metrics = evaluate_model_batched(\n",
    "    model=final_model,\n",
    "    test_data=test_users,\n",
    "    device=DEVICE,\n",
    "    target_return=None,\n",
    "    k_list=(5, 10, 20),\n",
    "    context_len=20,\n",
    "    eval_batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca864f-d6f5-4e65-b6ff-c05c9cbe0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles:\n",
      "  p25: 213.00\n",
      "  p50: 350.00\n",
      "  p75: 497.00\n",
      "  p90: 604.00\n",
      "  max: 849.00\n",
      "\n",
      "Evaluando con target_return = p25 (R=213.00)...\n"
     ]
    }
   ],
   "source": [
    "#Experimentos con valores de return to go\n",
    "# Usamos train_trajectories y test_users que ya cargamos arriba.\n",
    "trajectories = train_trajectories\n",
    "test_data = test_users\n",
    "\n",
    "# calcular percentiles de returns en training con numpy y los da en un diccionario\n",
    "train_returns = [traj['returns_to_go'][0] for traj in trajectories]\n",
    "\n",
    "percentiles = {\n",
    "    'p25': np.percentile(train_returns, 25),\n",
    "    'p50': np.percentile(train_returns, 50),\n",
    "    'p75': np.percentile(train_returns, 75),\n",
    "    'p90': np.percentile(train_returns, 90),\n",
    "    'max': np.max(train_returns)\n",
    "}\n",
    "#los printeamos para verlos \n",
    "print(\"Percentiles:\")\n",
    "for name, value in percentiles.items():\n",
    "    print(f\"  {name}: {value:.2f}\")\n",
    "\n",
    "# Acá en este ciclito for la idea es qeu te calcula las metricas para cada target return\n",
    "# y cada target retur es un percentil\n",
    "results = {}\n",
    "for name, rtg_value in percentiles.items():\n",
    "    print(f\"\\nEvaluando con target_return = {name} (R={rtg_value:.2f})...\")\n",
    "    metrics = evaluate_model_batched(\n",
    "        model=final_model,\n",
    "        test_data=test_data,\n",
    "        device=DEVICE,\n",
    "        target_return=rtg_value  # k_list usa el default [5, 10, 20]\n",
    "    )\n",
    "    results[name] = metrics\n",
    "    #y aca printeamos las metricas que venian del _baevaluate_model_batched\n",
    "    print(f\"  HR@10   = {metrics['HR@10']:.4f}\")\n",
    "    print(f\"  NDCG@10 = {metrics['NDCG@10']:.4f}\")\n",
    "    print(f\"  MRR     = {metrics['MRR']:.4f}\")\n",
    "\n",
    "# Graficar Return objetivo vs HR@10\n",
    "rtg_values = list(percentiles.values())\n",
    "hr10_values = [results[name]['HR@10'] for name in percentiles.keys()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(rtg_values, hr10_values, marker='o', linewidth=2)\n",
    "plt.xlabel('Target Return-to-go (R objetivo)')\n",
    "plt.ylabel('Hit Rate @10')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17f4c4-b7d3-4082-b12e-a04324d4e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HR@10   = 0.0150\n",
      "  NDCG@10 = 0.0065\n",
      "  MRR     = 0.0102\n",
      "\n",
      "  HR@10   = 0.0164\n",
      "  NDCG@10 = 0.0081\n",
      "  MRR     = 0.0112\n",
      "\n",
      "  HR@10   = 0.0123\n",
      "  NDCG@10 = 0.0061\n",
      "  MRR     = 0.0105\n",
      "\n",
      "  HR@10   = 0.0109\n",
      "  NDCG@10 = 0.0045\n",
      "  MRR     = 0.0088\n",
      "\n",
      "  HR@10   = 0.0137\n",
      "  NDCG@10 = 0.0068\n",
      "  MRR     = 0.0108\n",
      "\n",
      "  HR@10   = 0.0164\n",
      "  NDCG@10 = 0.0078\n",
      "  MRR     = 0.0111\n",
      "\n",
      "  HR@10   = 0.0123\n",
      "  NDCG@10 = 0.0079\n",
      "  MRR     = 0.0125\n",
      "\n",
      "  HR@10   = 0.0150\n",
      "  NDCG@10 = 0.0074\n",
      "  MRR     = 0.0109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usamos el percentil 75 de R_0 como target_return para todos los grupos porque alguno hay que usar. \n",
    "target_rtg_group = percentiles['p75'] #se puede hacer con otro si se cambia aca el percentil que se usa\n",
    "\n",
    "results_by_group = {}\n",
    "\n",
    "for group_id in range(8):\n",
    "    # hacemos un if para sacar los usuarios que pertenecen al grupo encuestión\n",
    "    users_in_group = [u for u in test_users if u['group'] == group_id]\n",
    "    metrics = evaluate_model_batched(\n",
    "        model=final_model,\n",
    "        test_data=users_in_group,\n",
    "        device=DEVICE,\n",
    "        target_return=target_rtg_group,\n",
    "        k_list=[5, 10, 20]\n",
    "    )\n",
    "    results_by_group[group_id] = metrics\n",
    "\n",
    "    #aca lo cambié para que imprima toda las métricas \n",
    "    print(f\"  HR@10   = {metrics['HR@10']:.4f}\")\n",
    "    print(f\"  NDCG@10 = {metrics['NDCG@10']:.4f}\")\n",
    "    print(f\"  MRR     = {metrics['MRR']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684a81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757719e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e68e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8d11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
